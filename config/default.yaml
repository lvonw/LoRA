# =============================================================================
# MAIN
# =============================================================================
Main:
  log level: debug
  base model: Llama-3.2-1B-Instruct
  Fine-Tuned Model:
    dataset:    numina-cot-100k
    method:     LoRA
    batch-size: 2
    epochs:     1
    
    framework: unsloth

Devices:
  idle_device: cpu

Inference:
  show input:           no
  skip special tokens:  no 

Fine-Tuning:
  batch-size: 4
  epochs:     1

  torchtune:
    external: config/torchtune/fine-tune.yaml
    selection: torchtune
    only_load_selection: yes
    read_only: no

Methods:
  methods:
    - LoRA
    - QLoRA

Frameworks:
  frameworks:
    - PEFT
    - unsloth
    - torchtune
    - Axolotl

Models:
  meta-llama: 
    - Llama-3.2-1B
    - Llama-3.2-1B-Instruct
    - Llama-3.2-3B
    - Llama-3.2-3B-Instruct
    - Llama-3.1-8B-Instruct
  mistralai:
    - Ministral-8B-Instruct-2410

Datasets:
  HuggingFaceTB:
    SmolTalk: 
      - all
      - apigen-80k
      - everyday-conversations
      - explore-instruct-rewriting
      - longalign
      - metamathqa-50k
      - numina-cot-100k
      - openhermes-100k
      - self-oss-instruct
      - smol-constraints
      - smol-magpie-ultra
      - smol-rewrite
      - smol-summorize
      - systemchats-30k


